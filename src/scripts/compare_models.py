import requests
import json
import time
import csv
import os
from datetime import datetime
from src.llm import get_llm
from langchain_core.messages import HumanMessage, SystemMessage

# Configuration
API_URL = "http://127.0.0.1:5001/analyze-json"
OUTPUT_FILE = "experiments/comparison_results.csv"

# The "Acid Test" Case (Complex Metabolic)
TEST_CASE = {
    "id": "CASE_003_COMPLEX_METABOLIC",
    "description": "Complex Metabolic - Multi-Agent Challenge",
    "patient": {"name": "Test Patient C", "sex": "M", "dob": "1975-08-20", "external_id": "P_COMPARE_001"},
    "tests": [
        {"code": "CREAT", "name": "Creatinine", "value": 1.6, "unit": "mg/dL", "flag": "High", "normal_range_low": 0.7, "normal_range_high": 1.3},
        {"code": "BUN", "name": "BUN", "value": 25, "unit": "mg/dL", "flag": "High", "normal_range_low": 7, "normal_range_high": 20},
        {"code": "K", "name": "Potassium", "value": 5.8, "unit": "mmol/L", "flag": "High", "normal_range_low": 3.5, "normal_range_high": 5.0},
        {"code": "GLU", "name": "Glucose", "value": 140, "unit": "mg/dL", "flag": "High", "normal_range_low": 70, "normal_range_high": 99}
    ],
    "medications": ["Lisinopril", "Ibuprofen"], 
    "medical_history": "Type 2 Diabetes, Chronic Back Pain"
}

def analyze_baseline_llm(case):
    """
    Simulates a standard "ChatGPT/Gemini" prompt without RAG or Agents.
    """
    print("   ü§ñ Running Baseline LLM (Vanilla)...")
    start_time = time.time()
    
    prompt = f"""
    You are a helpful AI doctor assistant. Analyze this patient report.
    
    Patient: {json.dumps(case['patient'])}
    Tests: {json.dumps(case['tests'])}
    Medications: {case['medications']}
    History: {case['medical_history']}
    
    Provide a summary and recommendations.
    """
    
    try:
        llm = get_llm()
        response = llm.invoke([HumanMessage(content=prompt)])
        content = response.content
        latency = round(time.time() - start_time, 2)
        return content, latency
    except Exception as e:
        print(f"   ‚ùå Baseline Error: {e}")
        return "", 0

def analyze_agentic_system(case):
    """
    Calls our Multi-Agent RAG API.
    """
    print("   üß† Running Agentic System (Ours)...")
    start_time = time.time()
    
    payload = {
        "current_report": {
            "patient": case["patient"],
            "tests": case["tests"],
            "report_date": "2023-10-27"
        },
        "medications": case["medications"],
        "medical_history": case["medical_history"],
        "knowledge_source": "hybrid"
    }

    try:
        # Long timeout for agentic processing
        response = requests.post(API_URL, json=payload, timeout=300)
        content = ""
        if response.status_code == 200:
            data = response.json()
            content = data.get("final_report", "")
        latency = round(time.time() - start_time, 2)
        return content, latency
    except Exception as e:
        print(f"   ‚ùå Agentic Error: {e}")
        return "", 0

def run_comparison():
    print(f"‚öñÔ∏è  Starting Model Comparison Experiment at {datetime.now()}")
    print("-" * 60)

    # 1. Run Baseline
    baseline_output, baseline_latency = analyze_baseline_llm(TEST_CASE)
    baseline_citations = baseline_output.count("[Ref")
    # Did it catch the Lisinopril + NSAID + Kidney Risk?
    baseline_safety_check = "Lisinopril" in baseline_output and ("profen" in baseline_output or "NSAID" in baseline_output) and ("Kidney" in baseline_output or "Renal" in baseline_output)

    print(f"   üëâ Baseline: {baseline_latency}s | Citations: {baseline_citations} | SafetyCheck: {baseline_safety_check}")
    
    # 2. Run Agentic
    # Cooldown to avoid Rate Limit from Baseline call
    time.sleep(10)
    agentic_output, agentic_latency = analyze_agentic_system(TEST_CASE)
    agentic_citations = agentic_output.count("[Ref")
    
    # Case-Insensitive Safety Check
    out_lower = agentic_output.lower()
    has_drug = "lisinopril" in out_lower
    has_nsaid = "profen" in out_lower or "nsaid" in out_lower or "advil" in out_lower
    has_kidney = "kidney" in out_lower or "renal" in out_lower or "nephro" in out_lower
    
    agentic_safety_check = has_drug and has_nsaid and has_kidney
    
    if not agentic_safety_check:
        print(f"   ‚ö†Ô∏è FAIL DEBUG: Drug={has_drug}, NSAID={has_nsaid}, Kidney={has_kidney}")
        print(f"   ‚ö†Ô∏è CONTENT SNIPPET: {agentic_output[:500]}...")

    print(f"   üëâ Agentic:  {agentic_latency}s | Citations: {agentic_citations} | SafetyCheck: {agentic_safety_check}")

    # 3. Save Results
    results = [
        {
            "Model": "Baseline (Vanilla LLM)",
            "Latency (s)": baseline_latency,
            "Citations (Grounding)": baseline_citations,
            "Risk Detection (Safety)": "PASS" if baseline_safety_check else "FAIL",
            "Output Length": len(baseline_output)
        },
        {
            "Model": "Agentic RAG (Ours)",
            "Latency (s)": agentic_latency,
            "Citations (Grounding)": agentic_citations,
            "Risk Detection (Safety)": "PASS" if agentic_safety_check else "FAIL",
            "Output Length": len(agentic_output)
        }
    ]

    with open(OUTPUT_FILE, 'w', newline='') as f:
        dict_writer = csv.DictWriter(f, fieldnames=results[0].keys())
        dict_writer.writeheader()
        dict_writer.writerows(results)

    print("-" * 60)
    print(f"üéâ Comparison Complete. Saved to {OUTPUT_FILE}")

if __name__ == "__main__":
    run_comparison()
